diff -urN kvm-84.old/kernel/x86/mmu.c kvm-84.new/kernel/x86/mmu.c
--- kvm-84.old/x86/mmu.c	2009-02-14 16:36:11.000000000 -0800
+++ kvm-84.new/x86/mmu.c	2009-03-15 04:52:52.204647760 -0700
@@ -513,6 +513,12 @@
 	unsigned long idx;
 
 	slot = gfn_to_memslot(kvm, gfn);
+
+	if (unlikely(!slot)) {
+		printk(KERN_ERR "%s(gfn %lx, lpage %d): cannot find memslot!\n", __func__, gfn, lpage);
+		BUG();
+	}
+
 	if (!lpage)
 		return &slot->rmap[gfn - slot->base_gfn];
 
@@ -1986,7 +1992,7 @@
 	vcpu->arch.mmu.root_hpa = INVALID_PAGE;
 }
 
-static void mmu_alloc_roots(struct kvm_vcpu *vcpu)
+static int mmu_alloc_roots(struct kvm_vcpu *vcpu)
 {
 	int i;
 	gfn_t root_gfn;
@@ -1996,6 +2002,19 @@
 	root_gfn = vcpu->arch.cr3 >> PAGE_SHIFT;
 
 	if (vcpu->arch.mmu.shadow_root_level == PT64_ROOT_LEVEL) {
+		/*
+		 * Verify that the root gfn is actually valid before continuing.
+		 * It could be invalid if userspace called KVM_SET_SREGS with a
+		 * bogus cr3. This could be exploited by malicious userspace
+		 * callers (particularly if non-root users can manipulate VMs)
+		 * or by a corrupted QEMU snapshot or migration. However, bogus
+		 * cr3 initiated *within* the VM are already checked elsewhere.
+		 */
+		if (unlikely(!gfn_to_memslot(vcpu->kvm, root_gfn))) {
+			printk(KERN_ERR "%s(vcpu %d): caller attempted to load a bogus root_gfn %lx\n", __func__, vcpu->vcpu_id, root_gfn);
+			return -EFAULT;
+		}
+
 		hpa_t root = vcpu->arch.mmu.root_hpa;
 
 		ASSERT(!VALID_PAGE(root));
@@ -2007,7 +2026,7 @@
 		root = __pa(sp->spt);
 		++sp->root_count;
 		vcpu->arch.mmu.root_hpa = root;
-		return;
+		return 0;
 	}
 	direct = !is_paging(vcpu);
 	if (tdp_enabled)
@@ -2024,6 +2043,13 @@
 			root_gfn = vcpu->arch.pdptrs[i] >> PAGE_SHIFT;
 		} else if (vcpu->arch.mmu.root_level == 0)
 			root_gfn = 0;
+
+		/* Verify that each PAE root gfn is actually valid before continuing. */
+		if (unlikely(!gfn_to_memslot(vcpu->kvm, root_gfn))) {
+			printk(KERN_ERR "%s(vcpu %d): caller attempted to load a bogus root_gfn %lx for PAE slot %d\n", __func__, vcpu->vcpu_id, root_gfn, i);
+			return -EFAULT;
+		}
+
 		sp = kvm_mmu_get_page(vcpu, root_gfn, i << 30,
 				      PT32_ROOT_LEVEL, direct,
 				      ACC_ALL, NULL);
@@ -2032,6 +2058,7 @@
 		vcpu->arch.mmu.pae_root[i] = root | PT_PRESENT_MASK;
 	}
 	vcpu->arch.mmu.root_hpa = __pa(vcpu->arch.mmu.pae_root);
+  return 0;
 }
 
 static void mmu_sync_roots(struct kvm_vcpu *vcpu)
@@ -2334,7 +2361,11 @@
 		goto out;
 	spin_lock(&vcpu->kvm->mmu_lock);
 	kvm_mmu_free_some_pages(vcpu);
-	mmu_alloc_roots(vcpu);
+	r = mmu_alloc_roots(vcpu);
+	if (r) {
+		spin_unlock(&vcpu->kvm->mmu_lock);
+		goto out;
+	}
 	mmu_sync_roots(vcpu);
 	spin_unlock(&vcpu->kvm->mmu_lock);
 	kvm_x86_ops->set_cr3(vcpu, vcpu->arch.mmu.root_hpa);

 	  	 
